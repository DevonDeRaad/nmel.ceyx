---
title: "ceyx.snp.filtering"
format:
  html:
    code-fold: show
    code-tools: true
toc: true
toc-title: Document Contents
number-sections: true
embed-resources: true
bibliography: references.bib
---

<iframe src="https://macaulaylibrary.org/asset/608391932/embed" height="500" width="640" frameborder="0" allowfullscreen>

</iframe>

## Load packages and read in unfiltered vcf {style="color: blue"}

This vcf comes straight out of mapping raw RADseq reads to a publicly available *Ceyx* reference genome and calling SNPs using Stacks [@rochette2019] (exact pipeline used for this dataset is available [here](https://github.com/DevonDeRaad/nmel.ceyx/blob/main/raw.sequence.data.to.snps/map.and.run.stacks.sh)).

```{r}
#| output: false
library(vcfR)
library(SNPfiltR)
library(StAMPP)
library(adegenet)
library(ggplot2)
#read vcf
v<-read.vcfR("~/Desktop/nmel.ceyx.rad/populations.snps.vcf.gz")
```

I will now follow the SNP filtering pipeline outlined in detail in the documents of the SNPfiltR R package (see [SNPfiltR vignettes](https://devonderaad.github.io/SNPfiltR/)) [@deraad2022]

## Implement quality filters that don't involve missing data

This is because removing low data samples will alter percentage/quantile based missing data cutoffs, so we wait to implement those until after deciding on our final set of samples for downstream analysis

```{r}
#| layout-ncol: 3
#| column: page

#visualize distributions
hard_filter(v)

#hard filter to minimum depth of 3, and minimum genotype quality of 30
v<-hard_filter(vcfR=v, depth = 3, gq = 30)
```

Use the function `allele_balance()` to filter for allele balance from [Puritz SNP filtering tutorial](http://www.ddocent.com/filtering/) "Allele balance: a number between 0 and 1 representing the ratio of reads showing the reference allele to all reads, considering only reads from individuals called as heterozygous, we expect that the allele balance in our data (for real loci) should be close to 0.5"

```{r}
#execute allele balance filter
v<-filter_allele_balance(v, min.ratio = .1, max.ratio = .9)
```

We now want to implement a max depth filter (super high depth loci are likely multiple loci stuck together into a single paralogous locus, which we want to remove).

```{r}
#| layout-ncol: 3
#| column: page

#visualize and pick appropriate max depth cutoff
max_depth(v)

#filter vcf by the max depth cutoff you chose
v<-max_depth(v, maxdepth = 250)
```

Remove SNPs from the vcfR that have become invariant following the removal of questionable genotypes above, and see how many SNPs we have left after this initial set of filters

```{r}
v<-min_mac(v, min.mac = 1)
v
```

## Setting the missing data by sample threshold

Check out the exploratory visualizations and make decisions about which samples to keep for downstream analysis.

```{r}
#run function to visualize per sample missingness
miss<-missing_by_sample(v)
```

```{r}
#run function to visualize per SNP missingness
by.snp<-missing_by_snp(v)
```

Based on these visualizations, we will want to drop the worst sequenced samples that are dragging down the rest of the dataset. Drop those samples based on an approximate missing data proportion cutoff here (this can always be revised if we end up feeling like this is too lenient or stringent later):

```{r}
#run function to drop samples above the threshold we want from the vcf
vcfR.trim<-missing_by_sample(v, cutoff = .8)
#remove invariant sites generated by sample trimming
vcfR.trim<-min_mac(vcfR.trim, min.mac = 1)

#see what effect trimming samples had on missing data across the dataset
by.snp<-missing_by_snp(vcfR.trim)
```

## Assess technical replicates

To investigate evidence for technical error, batch effects, or contamination, I will compare patterns of sample clustering among all samples with technical replicates still included in the dataset.

```{r}
#set 90% completeness per SNP threshold
test<-missing_by_snp(vcfR.trim, cutoff=.9)
#convert to genlight
gen<-vcfR2genlight(test)
#fix sample names to fit in <= 10 characters
gen@ind.names
gen@ind.names<-gsub("C_collectoris","co", gen@ind.names)
gen@ind.names<-gsub("C_margarethae","mar", gen@ind.names)
gen@ind.names<-gsub("C_gentianus","gen", gen@ind.names)
gen@ind.names<-gsub("C_solitarius","sol", gen@ind.names)
gen@ind.names<-gsub("C_nigromaxilla","ni", gen@ind.names)
gen@ind.names<-gsub("C_malaitae","ml", gen@ind.names)
gen@ind.names<-gsub("C_meeki","me", gen@ind.names)
gen@ind.names<-gsub("C_dispar","dis", gen@ind.names)
gen@ind.names<-gsub("C_sacerdotis","sac", gen@ind.names)
gen@ind.names<-gsub("C_mulcatus","mul", gen@ind.names)
gen@ind.names
pop(gen)<-gen@ind.names
#assign populations (a StaMPP requirement)
gen@pop<-as.factor(gen@ind.names)
#generate pairwise divergence matrix
sample.div <- stamppNeisD(gen, pop = FALSE)
#export for splitstree
stamppPhylip(distance.mat=sample.div, file="~/Desktop/nmel.ceyx.rad/test.90.splits.txt")

#view tree
knitr::include_graphics("/Users/devonderaad/Desktop/ceyx.tree.png")

#view zoomed patterns of clustering which show technical replicates tightly clustered
knitr::include_graphics("/Users/devonderaad/Desktop/tech.reps1.png")
knitr::include_graphics("/Users/devonderaad/Desktop/tech.reps2.png")
knitr::include_graphics("/Users/devonderaad/Desktop/tech.reps3.png")
knitr::include_graphics("/Users/devonderaad/Desktop/tech.reps4.png")
```

I will now investigate the number of genotypes that differ between technical replicates which were derived from the same DNA extract, in this filtered, 85% complete dataset

```{r}
#define function to calculate degree of genotype conflict between technical replicates
assess_technical_reps<-function(vcf=NULL, rep1=NULL, rep2=NULL){
  #print percentage of called genotypes that differ between reps
  zz<-table(gsub(":.*","",(test@gt[,colnames(vcf@gt) == rep1])) == gsub(":.*","",(vcf@gt[,colnames(test@gt) == rep2])))
  print(paste0("percentage of called SNPs where genotypes differ between ", rep1," and ",rep2," = ",round(zz[1]*100/sum(zz), 3),"%."))
  #isolate the exact genotypes that conflict
  z<-gsub(":.*","",(vcf@gt[,colnames(vcf@gt) == rep1 | colnames(vcf@gt) ==   rep2]))[gsub(":.*","",(vcf@gt[,colnames(vcf@gt) == rep1])) !=   gsub(":.*","",(vcf@gt[,colnames(vcf@gt) == rep2])),]
  #print them with missing values removed
  print(paste0("Conflicting genotypes printed below"))
  z[complete.cases(z), ]
}

#assess all possible comparisons
assess_technical_reps(vcf=test, "C_collectoris_33272", "C_collectoris_33272-2")
assess_technical_reps(vcf=test, "C_collectoris_33274", "C_collectoris_33274-2")
assess_technical_reps(vcf=test, "C_meeki_5633", "C_meeki_5633-2")
assess_technical_reps(vcf=test, "C_meeki_32075", "C_meeki_32075-2")
assess_technical_reps(vcf=test, "C_meeki_32075", "C_meeki_32075-3")
assess_technical_reps(vcf=test, "C_meeki_32075-2", "C_meeki_32075-3")
assess_technical_reps(vcf=test, "C_malaitae_32790", "C_malaitae_32790-2")
assess_technical_reps(vcf=test, "C_dispar_5611", "C_dispar_5611-2")
```

These results suggest a technical error rate between .04 - .41 % based on genotype calling in technical replicates derived from the same DNA extracts. This error rate is likely highly dependent on depth of sequencing, as disagreements between called genotypes are nearly universally cases where one replicate is called heterozygous and the other is not. These cases depend greatly on the depth of sequencing to accurately recover enough reads for confident het calls. These results suggest an overall low technical error rate and no evidence for batch effects or contamination.

I will now remove the lower sequenced replicate for each technical replicate, leaving us with a dataset where each replicate comes from a unique biological sample

```{r}
#remove lower sequenced samples when there are multiple replicates
vcfR.trim<-vcfR.trim[,colnames(vcfR.trim@gt) != "C_collectoris_33272-2" &
      colnames(vcfR.trim@gt) != "C_collectoris_33274-2" &
       colnames(vcfR.trim@gt) != "C_meeki_5633-2" &
       colnames(vcfR.trim@gt) != "C_meeki_32075-3" &
       colnames(vcfR.trim@gt) != "C_meeki_32075-2" &
       colnames(vcfR.trim@gt) != "C_malaitae_32740-2" &
       colnames(vcfR.trim@gt) != "C_malaitae_32790" &
       colnames(vcfR.trim@gt) != "C_dispar_5611"]

#remove invariant SNPs
vcfR.trim<-min_mac(vcfR.trim, min.mac = 1)
```

## Setting the missing data by SNP threshold

Now we will visualize different per SNP missing data thresholds and identify a value that optimizes the trade-off between amount of missing data and the total number of SNPs retained.

```{r}
#see what effect trimming samples and technical replicates has had on missing data across the dataset
by.snp<-missing_by_snp(vcfR.trim)
```

Set a 90% per-SNP completeness cutoff which seems sufficient for a high quality dataset
```{r}
#set 90% completeness per SNP threshold
filt<-missing_by_snp(vcfR.trim, cutoff=.9)
bysamp<-missing_by_sample(filt)
filt
#convert to genlight
gen<-vcfR2genlight(filt)
#fix sample names to fit in <= 10 characters
gen@ind.names
gen@ind.names<-gsub("C_collectoris","co", gen@ind.names)
gen@ind.names<-gsub("C_margarethae","mar", gen@ind.names)
gen@ind.names<-gsub("C_gentianus","gen", gen@ind.names)
gen@ind.names<-gsub("C_solitarius","sol", gen@ind.names)
gen@ind.names<-gsub("C_nigromaxilla","ni", gen@ind.names)
gen@ind.names<-gsub("C_malaitae","ml", gen@ind.names)
gen@ind.names<-gsub("C_meeki","me", gen@ind.names)
gen@ind.names<-gsub("C_dispar","dis", gen@ind.names)
gen@ind.names<-gsub("C_sacerdotis","sac", gen@ind.names)
gen@ind.names<-gsub("C_mulcatus","mul", gen@ind.names)
gen@ind.names
pop(gen)<-gen@ind.names
#assign populations (a StaMPP requirement)
gen@pop<-as.factor(gen@ind.names)
#generate pairwise divergence matrix
sample.div <- stamppNeisD(gen, pop = FALSE)
#export for splitstree
stamppPhylip(distance.mat=sample.div, file="~/Desktop/nmel.ceyx.rad/ceyx.90.splits.txt")

#splitstree looks clean, no evidence of weird clustering driven by missing data
knitr::include_graphics("/Users/devonderaad/Desktop/ceyx.90.splits.png")
```

## Remove overlapping SNPs

It is a known thing (see [this](https://groups.google.com/g/stacks-users/c/Ag8YyEFe7z0)) that Stacks will not merge SNPs if they are sequenced by separate (but physically overlapping) loci, and will instead retain the same SNP twice. To account for this, we will simply remove a SNP every time its chromosome and position have already been seen in the dataset, using the following code:

```{r}
#generate dataframe containing information for chromosome and bp locality of each SNP
df<-as.data.frame(filt@fix[,1:2])
#calc number of duplicated SNPs to remove
nrow(df) - length(unique(paste(df$CHROM,df$POS)))
#remove duplicated SNPs
filt<-filt[!duplicated(paste(df$CHROM,df$POS)),]
```

## Visualize depth and quality across all retained genotypes

```{r}
#plot depth per snp and per sample
dp <- extract.gt(filt, element = "DP", as.numeric=TRUE)
heatmap.bp(dp, rlabels = FALSE)

#plot genotype quality per snp and per sample
gq <- extract.gt(filt, element = "GQ", as.numeric=TRUE)
heatmap.bp(gq, rlabels = FALSE)
```

## linkage filter

Now filter for linkage

```{r}
#perform linkage filtering to get a reduced vcf with only unlinked SNPs
filt.thin<-distance_thin(filt, min.distance = 10000)
```

## write vcf to disk for downstream analyses

```{r}
#get info for all SNPs passing filtering vcf dataset
filt
#write to disk
#vcfR::write.vcf(filt, file = "~/Desktop/nmel.ceyx.rad/filtered.snps.vcf.gz")

#get info for the thinned SNP dataset
filt.thin
#write to disk
#vcfR::write.vcf(filt.thin, file = "~/Desktop/nmel.ceyx.rad/filtered.unlinked.snps.vcf.gz")
```
